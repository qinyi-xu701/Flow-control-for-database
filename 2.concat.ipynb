{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Package and set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QiXu260'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from datetime import date\n",
    "import shutil\n",
    "import getpass\n",
    "\n",
    "username = getpass.getuser()\n",
    "username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home and time\n",
    "home = os.path.expanduser(\"~\")\n",
    "todaystr = date.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# set up concat directories\n",
    "if username == 'panj':\n",
    "    targetFolder = os.path.join(home,'New OneDrive', 'HP Inc','GPS TW Innovation - 文件','Project team','Project RiXin - Shortage management', 'Upload_folder') # Jesse\n",
    "else:\n",
    "    targetFolder = os.path.join(home, 'New OneDrive', 'HP Inc','GPS TW Innovation - Documents','Project team','Project RiXin - Shortage management', 'Upload_folder') # Dustin\n",
    "\n",
    "# folders\n",
    "FD_folder = os.path.join(targetFolder, \"FD_today\")\n",
    "shortage_folder = os.path.join(targetFolder ,\"shortage_today\")\n",
    "PNbasedDetail_folder = os.path.join(targetFolder ,\"PNbasedDetail_today\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amend data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FD_amend_folder = os.path.join(targetFolder, \"FD_today\", 'amend')\n",
    "shortage_amend_folder = os.path.join(targetFolder ,\"shortage_today\",'amend')\n",
    "PNbasedDetail_amend_folder = os.path.join(targetFolder ,\"PNbasedDetail_today\",'amend')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Merge and Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(path: str) -> pd.DataFrame:\n",
    "    # concat\n",
    "    temp_file_list = []\n",
    "    for f in glob.glob(path):\n",
    "        # print(f)\n",
    "        temp_file = pd.read_excel(f)\n",
    "        temp_file_list.append(temp_file)\n",
    "    All = pd.concat(temp_file_list)\n",
    "    \n",
    "    return All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxLen(df_all: pd.DataFrame, sort_index: list) -> pd.DataFrame:\n",
    "    # sort based on len\n",
    "    sort_list = []\n",
    "    for _ in sort_index:\n",
    "        try:\n",
    "            df_all[str('len_' + _)] = df_all[_].str.len()\n",
    "            sort_list.append(str('len_' + _))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    df_all = df_all.reset_index(drop = True)\n",
    "\n",
    "    max_files = []\n",
    "    for i, ele in enumerate(sort_list):\n",
    "        idmax = df_all[ele].max()\n",
    "        max = df_all[df_all[ele] == idmax]\n",
    "        max_files.append(max.head(1))\n",
    "    df_max_to_add = pd.concat(max_files).drop_duplicates()\n",
    "\n",
    "    # print(df_max_to_add.index.values)\n",
    "    df_max_to_add.index.values.sort()\n",
    "    # print(df_max_to_add.index.values)\n",
    "\n",
    "\n",
    "    # drop the max len row\n",
    "    for i, ele in enumerate(df_max_to_add.index.values):\n",
    "        df_all = df_all.drop([df_all.index[ele - i]])\n",
    "\n",
    "    # concat and put on the top\n",
    "    output = pd.concat([df_max_to_add, df_all]).reset_index( drop = True )\n",
    "\n",
    "    # cut more than 500\n",
    "    for _ in sort_index:\n",
    "        try:\n",
    "            output[_] = output[_].apply(lambda x: x[:450] if len(x) > 500 else x)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    # final step, drop calculate step and output\n",
    "    output = output.drop(columns = sort_list)\n",
    "    output['Item'] = output['Item'].astype(str)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate FD, shortage, PNDetail table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can only use .str accessor with string values!\n",
      "object of type 'float' has no len()\n",
      "object of type 'float' has no len()\n",
      "object of type 'float' has no len()\n",
      "object of type 'float' has no len()\n",
      "object of type 'float' has no len()\n",
      "object of type 'float' has no len()\n"
     ]
    }
   ],
   "source": [
    "FD = merge(str(os.path.join(FD_folder,\"*.xlsx\")))\n",
    "try:\n",
    "    FD_output = maxLen(FD, ['FV','Platform'])\n",
    "except ValueError:\n",
    "    FD_output = FD.copy()\n",
    "FD_output.drop_duplicates(subset=['ReportDate', 'ODM','Item','Commodity','FV','HP_PN','FDdate','FDQty'], inplace=True)\n",
    "FD_output.replace({\"'\": \"\"}, regex = True, inplace = True)\n",
    "\n",
    "shortage = merge(str(os.path.join(shortage_folder,\"*.xlsx\")))\n",
    "try:\n",
    "    shortage['HP_PN'] = shortage['HP_PN'].apply(lambda x: x[:128] if len(x) > 128 else x)\n",
    "except:    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    Shortage_output = maxLen(shortage, ['FV','Platform'])\n",
    "except ValueError:\n",
    "    Shortage_output = shortage.copy()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "Shortage_output.drop_duplicates(subset=['ReportDate', 'ODM','Item','Commodity','FV'], inplace=True)\n",
    "Shortage_output.replace({\"'\": \"\"}, regex = True, inplace = True)\n",
    "\n",
    "\n",
    "PN = merge(str(os.path.join(PNbasedDetail_folder,\"*.xlsx\")))\n",
    "try:\n",
    "    PNbasedDetail_output = maxLen(PN, ['BSP Remark','ODM use column1','ODM use column2','ODM use column3','ODM use column4','ODM use column5'])\n",
    "except ValueError:\n",
    "    PNbasedDetail_output = PN.copy()\n",
    "# PNbasedDetail_output = PN.copy()\n",
    "PNbasedDetail_output.drop_duplicates(subset=['ReportDate', 'ODM','Item','Commodity','HP PN'], inplace=True)\n",
    "PNbasedDetail_output.replace({\"'\": \"\"}, regex = True, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output concated FD, Shortage, and PNbasedDetail files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apache airflow to upload SQL ( currently to desktop )\n",
    "FD_output.to_excel(os.path.join(home, 'Desktop', 'FD_all.xlsx'), index=False)\n",
    "Shortage_output.to_excel(os.path.join(home, 'Desktop', 'Shortage_all.xlsx'), index=False)\n",
    "PNbasedDetail_output.to_excel(os.path.join(home, 'Desktop', 'PNbasedDetail_all.xlsx'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move file to archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FD_folder = os.path.join(targetFolder, \"FD_today\")\n",
    "FD_archive_folder = os.path.join(targetFolder, 'FD_Archive')\n",
    "\n",
    "for f in os.listdir(FD_folder):\n",
    "    if f.endswith('.xlsx'):\n",
    "        shutil.move(os.path.join(FD_folder, f), os.path.join(FD_archive_folder, f))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "shortage_folder = os.path.join(targetFolder ,\"shortage_today\")\n",
    "shortage_archive_folder = os.path.join(targetFolder ,\"Shortage_Archive\")\n",
    "\n",
    "for f in os.listdir(shortage_folder):\n",
    "    if f.endswith('.xlsx'):\n",
    "        shutil.move(os.path.join(shortage_folder, f), os.path.join(shortage_archive_folder, f))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "PNbasedDetail_folder = os.path.join(targetFolder ,\"PNbasedDetail_today\")\n",
    "PNbasedDetail_archive_folder = os.path.join(targetFolder ,\"PNbasedDetail_Archive\")\n",
    "\n",
    "for f in os.listdir(PNbasedDetail_folder):\n",
    "    if f.endswith('.xlsx'):\n",
    "        shutil.move(os.path.join(PNbasedDetail_folder, f), os.path.join(PNbasedDetail_archive_folder, f))\n",
    "    else:\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aff61a50ca05787580f84e419a783e3027ed4326834427d692766cd5b4e8a2a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
