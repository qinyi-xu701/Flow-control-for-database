{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages and username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hsudu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "import pyodbc\n",
    "import shutil\n",
    "import getpass\n",
    "\n",
    "# path \n",
    "home = Path.home()\n",
    "today = dt.today().date()\n",
    "\n",
    "# username for collaboration\n",
    "username = getpass.getuser()\n",
    "username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define path and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dateragnes\n",
    "dateRange = [today - timedelta(days = x) for x in range(365)]\n",
    "# dateRange = [i.strftime(\"%Y%m%d\") for i in dateRange]\n",
    "\n",
    "# change type\n",
    "today = today.strftime(\"%Y%m%d\")\n",
    "\n",
    "ODMdict = {\n",
    "    'FWH' : 'WHFXN',\n",
    "    'FXN' : 'WHFXN',\n",
    "    'Foxconn WH' : 'WHFXN',\n",
    "    'Compal' : 'KSCEI',\n",
    "    'CEI' : 'KSCEI',\n",
    "    'Wistron' : 'CQWIS',\n",
    "    'wistron' : 'CQWIS',\n",
    "    'Wistron CQ': 'CQWCQ',\n",
    "    'WCQ': 'CQWIS',\n",
    "    'Inventec' : 'CQIEC',\n",
    "    'Inventec CQ' : 'CQIEC',\n",
    "    'Quanta' : 'CQQCI',\n",
    "    'Quanta CQ' : 'CQQCI',\n",
    "    'Pegatron' : 'CQPCQ'\n",
    "}\n",
    "\n",
    "# reverse date range to correct sort\n",
    "dateRange.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path\n",
    "if username == 'panj':\n",
    "    path = os.path.join(home, 'HP Inc','GPS TW Innovation - 文件','Project team','Project RiXin - Shortage management') # Jesse \n",
    "else:\n",
    "    path = os.path.join(home, 'HP Inc','GPS TW Innovation - Documents','Project team','Project RiXin - Shortage management') # Dustin\n",
    "\n",
    "# define path\n",
    "if username == 'panj':\n",
    "    PNFVPath = Path(home, 'HP Inc', 'GPS TW Innovation - 文件', 'Users', 'GPS','Shortage management related (Ri Xin)', 'PN FV description mapping table_ALL.xlsx') # Jesse\n",
    "else:\n",
    "    PNFVPath = Path(home, 'HP Inc', 'GPS TW Innovation - Documents', 'Users', 'GPS','Shortage management related (Ri Xin)', 'PN FV description mapping table_ALL.xlsx') # Dustin\n",
    "\n",
    "# read critical shortage file, external report, and PNFV table\n",
    "target = Path (path,'Single shortage')\n",
    "ExternalReportFolder = Path(path, 'External_Destination', 'today')\n",
    "PNFVFile = pd.read_excel(PNFVPath)\n",
    "PNFVFile = PNFVFile [['PN', 'Descr']]\n",
    "PNFVFile = PNFVFile.rename(columns = {'PN': 'HP PN'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is tool clean the external \n",
    "def clean(fname: str, file : pd.DataFrame, externalReportDate : str) -> pd.DataFrame:\n",
    "\n",
    "    currentYear = dt.now().year\n",
    "    currentday = fname.split('\\\\')[-1][-13:-5]\n",
    "    file = file.assign(LastSGreportDate = currentday)\n",
    "    \n",
    "    file['LastSGreportDate'] = file['LastSGreportDate'].apply(lambda x: dt.strptime(x, '%Y%m%d'))\n",
    "    file['LastSGreportDate'] = pd.to_datetime(file['LastSGreportDate'])\n",
    "\n",
    "    file = file.assign(reportDate = externalReportDate)\n",
    "\n",
    "    file['reportDate'] = file['reportDate'].apply(lambda x: dt.strptime(x, '%Y%m%d'))\n",
    "    file['reportDate'] = pd.to_datetime(file['reportDate'])\n",
    "\n",
    "    file['HP PN'] = file['HP PN'].apply(lambda x: x[:10])\n",
    "\n",
    "    # clean\n",
    "    file.columns = file.columns.str.strip()\n",
    "    \n",
    "    # replace ODM name\n",
    "    file['ODM'] = file['ODM'].replace(ODMdict)\n",
    "    return file   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create date key for lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x1f452c0bfc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get today's file from archieved folder\n",
    "fileList = [str(x) for x in Path(target,'Archive').glob(\"*xlsx\")]\n",
    "fileListDateNum = [dt.strptime(x[-13:-5], \"%Y%m%d\").date() for x in fileList]\n",
    "\n",
    "errorList = []\n",
    "resultList = []\n",
    "lookupSGdateList = []\n",
    "\n",
    "# create the tuple list looking for critical shortage\n",
    "i = 0\n",
    "for _ in dateRange:\n",
    "    if i == len(fileListDateNum)-1:\n",
    "        lookupSGdateList.append(fileListDateNum[i])\n",
    "        continue\n",
    "    \n",
    "    if _ < fileListDateNum[i+1]:\n",
    "        lookupSGdateList.append(fileListDateNum[i])\n",
    "    else:\n",
    "        i = i + 1\n",
    "        lookupSGdateList.append(fileListDateNum[i])\n",
    "\n",
    "# clean up key format\n",
    "dateRange = [i.strftime(\"%Y%m%d\") for i in dateRange]\n",
    "lookupSGdateList = [i.strftime(\"%Y%m%d\") for i in lookupSGdateList]\n",
    "zip(dateRange, lookupSGdateList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addKey(res: pd.DataFrame) -> tuple[list, pd.DataFrame]:\n",
    "    LatestSGMaterial = res\n",
    "    LatestSGMaterial = LatestSGMaterial.merge(PNFVFile, on = 'HP PN', how = 'left')\n",
    "    LatestSGMaterial['Key'] = LatestSGMaterial['ODM'] + LatestSGMaterial['Descr']\n",
    "    KeyList = LatestSGMaterial['Key'].tolist()\n",
    "    print(\"addKey done!\")\n",
    "    return KeyList, res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat current day external report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatExternal(extReportPathList: list, KeyList: list) -> pd.DataFrame:\n",
    "    externalResultDFList = []\n",
    "    if not extReportPathList:\n",
    "        return \n",
    "\n",
    "    for _ in extReportPathList:\n",
    "        try: \n",
    "            temp = pd.read_excel(_)\n",
    "            temp['ODM'] = temp['ODM'].ffill()\n",
    "            temp['ODM'] = temp['ODM'].replace(ODMdict)\n",
    "            temp['FV/Des'] = temp['FV/Des'].ffill()\n",
    "            #temp['ETA'] = temp['ETA'].ffill()\n",
    "            temp['key'] = temp['ODM'] + temp['FV/Des']\n",
    "            temp = temp[temp.key.isin(KeyList)]\n",
    "            \n",
    "            try:\n",
    "                temp = temp[['ODM', 'FV/Des', 'HP_PN', 'ETA', 'GPS Remark']]\n",
    "            except:\n",
    "                temp = temp[['ODM', 'FV/Des', 'HP PN', 'ETA', 'GPS Remark']]\n",
    "                temp = temp.rename(columns = {'HP PN' : 'HP_PN'})\n",
    "                print(\"Rocky wrong format!\")\n",
    "                \n",
    "            temp = temp.groupby(['ODM', 'FV/Des']).agg({'ETA' : lambda x: '\\n'.join(set(x.dropna())),\n",
    "                                                        'GPS Remark': lambda x: '\\n'.join(set(x.dropna()))})\n",
    "            temp = temp.reset_index()\n",
    "            if len(temp) > 0:\n",
    "                print(len(temp))\n",
    "                externalResultDFList.append(temp)\n",
    "            else:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(_)\n",
    "    try:\n",
    "        externalResultDF = pd.concat(externalResultDFList)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"No single shortage match!\")\n",
    "        return pd.DataFrame(columns = ['ODM', 'FV/Des', 'HP_PN', 'ETA', 'GPS Remark'])\n",
    "    print('External process done!')\n",
    "    return externalResultDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup PNFV and merge external reportm then output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeNoutput(SGres: pd.DataFrame, extRes: pd.DataFrame, dateStr: str) -> None:\n",
    "\n",
    "    # give new FV based on PN on single shortage \n",
    "    SGres = SGres.merge(PNFVFile.rename(columns = {'PN': 'HP PN'}), on = 'HP PN', how = 'left')\n",
    "    # merge FD on FV\n",
    "    SGres = SGres.merge(extRes.rename(columns = {'FV/Des' : 'Descr'}), on = ['ODM', 'Descr'], how = 'left')\n",
    "    SGres = SGres.drop_duplicates()\n",
    "    # \n",
    "    SGres.to_excel(Path(target, 'test','total singal shortage_' + dateStr +'.xlsx'), index = False)\n",
    "    print(\"Output done!\")\n",
    "    return SGres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hsudu\\\\HP Inc\\\\GPS TW Innovation - Documents\\\\Project team\\\\Project RiXin - Shortage management\\\\Single shortage\\\\Single shortage 20231230.xlsx'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverse for sorting\n",
    "dateRange.reverse()\n",
    "lookupSGdateList.reverse()\n",
    "\n",
    "# for i, j in zip(dateRange[0], lookupSGdateList[0]):\n",
    "#     print(i, j)\n",
    "\n",
    "# glob all file in single shortage to check which file\n",
    "[f for f in glob.glob(str(Path(target, 'Single shortage ' + '*')))][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsudu\\HP Inc\\GPS TW Innovation - Documents\\Project team\\Project RiXin - Shortage management\\Single shortage\\Single shortage 20231230.xlsx process done!\n",
      "addKey done!\n",
      "1\n",
      "External process done!\n",
      "Output done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Critical shortage qty</th>\n",
       "      <th>ODM</th>\n",
       "      <th>Description (Item)</th>\n",
       "      <th>HP PN</th>\n",
       "      <th>Remark</th>\n",
       "      <th>LastSGreportDate</th>\n",
       "      <th>reportDate</th>\n",
       "      <th>Descr</th>\n",
       "      <th>ETA</th>\n",
       "      <th>GPS Remark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SSS</td>\n",
       "      <td>11</td>\n",
       "      <td>CQIEC</td>\n",
       "      <td>SSD 4TB 2280 M2 PCIE 4x4 NVME TLC</td>\n",
       "      <td>N12390-001</td>\n",
       "      <td>Pull-in ASAP</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>2024-03-08</td>\n",
       "      <td>SSD 4TB 2280 M2 PCIE 4x4 NVME TLC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Commodity  Critical shortage qty    ODM                 Description (Item)  \\\n",
       "0       SSS                     11  CQIEC  SSD 4TB 2280 M2 PCIE 4x4 NVME TLC   \n",
       "\n",
       "        HP PN        Remark LastSGreportDate reportDate  \\\n",
       "0  N12390-001  Pull-in ASAP       2023-12-30 2024-03-08   \n",
       "\n",
       "                               Descr ETA GPS Remark  \n",
       "0  SSD 4TB 2280 M2 PCIE 4x4 NVME TLC                 "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et = today\n",
    "# et = '20231229'\n",
    "# sg = '20230209'\n",
    "\n",
    "fname = [f for f in glob.glob(str(Path(target, 'Single shortage ' + '*')))][-1]\n",
    "ExternalReport = [f for f in glob.glob(str(Path(ExternalReportFolder, et + '*')))]\n",
    "\n",
    "if not ExternalReport:\n",
    "    print(\"No external on \" + et)\n",
    "    # exit()\n",
    "try:\n",
    "    file = pd.read_excel(str(fname))\n",
    "    sg_res = clean(str(fname), file, et)\n",
    "    print(str(fname) + \" process done!\")\n",
    "except Exception as e:\n",
    "    errorList.append([str(fname), e])\n",
    "    print(e)\n",
    "    print(str(fname) + \" process failed!\")\n",
    "    # exit()\n",
    "\n",
    "k, sg_res = addKey(sg_res)\n",
    "ext_res = concatExternal(ExternalReport, k)\n",
    "if ext_res is None:\n",
    "    print(\"No external on \" + et)\n",
    "    # exit()\n",
    "\n",
    "sg_result = mergeNoutput(sg_res, ext_res, et)\n",
    "sg_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to single shortage table\n",
    "conn = pyodbc.connect('Driver={SQL Server Native Client 11.0}; Server=g7w11206g.inc.hpicorp.net; Database=CSI; Trusted_Connection=Yes;')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# clean up to prevent error\n",
    "sg_result['ETA'] = sg_result['ETA'].apply(lambda x: x.replace(\"'\",\"\") if type(x) == str else x)\n",
    "\n",
    "# upload rows by rows\n",
    "for index, row in sg_result.iterrows():\n",
    "    sg_Commodity = row['Commodity']\n",
    "    sg_Qty = row['Critical shortage qty']\n",
    "    sg_ODM = row['ODM']\n",
    "    sg_PN_all = row['HP PN']\n",
    "    sg_reportDate = row['reportDate']\n",
    "    sg_ETA = row['ETA']\n",
    "    sg_gpsRemark = row['GPS Remark']\n",
    "\n",
    "    # Corrected SQL INSERT statement\n",
    "    cursor.execute(f\"\"\"\n",
    "        INSERT INTO CSI.OPS.GPS_tbl_ops_Single_shortage \n",
    "        (Commodity, [Single Shortage QTY], ODM, [HP PN], reportDate, ETA, [GPS Remark])\n",
    "        VALUES ('{sg_Commodity}', '{sg_Qty}', '{sg_ODM}', '{sg_PN_all}', '{sg_reportDate}', '{sg_ETA}', '{sg_gpsRemark}')\n",
    "        \"\"\".replace(\"'NaT'\", \"NULL\").replace(\"'nan'\", \"NULL\"))\n",
    "\n",
    "# remember to close\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send external to archieved\n",
    "ExternalreportArchiveFolder = os.path.join(path, 'External_Destination', 'Archive')\n",
    "\n",
    "for f in os.listdir(ExternalReportFolder):\n",
    "    if f.endswith('.xlsx'):\n",
    "        shutil.move(os.path.join(ExternalReportFolder, f), os.path.join(ExternalreportArchiveFolder, f))\n",
    "\n",
    "for f in os.listdir(os.path.join(ExternalReportFolder, 'amend')):\n",
    "    if f.endswith('.xlsx'):\n",
    "        shutil.move(os.path.join(ExternalReportFolder, 'amend', f), os.path.join(ExternalreportArchiveFolder, f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cadcbe1cf7f77607d04fb86883766795fe82998168b094e073d163801885097d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
